{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4717323e",
   "metadata": {},
   "source": [
    "# Pipeline completo: Preprocesado, Modelado y Evaluación en Google Colab\n",
    "Este notebook ejecuta el flujo completo para clasificación de tumores cerebrales en imágenes MRI: descarga/preprocesado, entrenamiento de un modelo CNN y evaluación.\n",
    "\n",
    "---\n",
    "\n",
    "**Flujo del notebook:**\n",
    "1. Instalación de dependencias y configuración de entorno\n",
    "2. Descarga y organización del dataset\n",
    "3. Preprocesado y guardado de imágenes\n",
    "4. Preparación de arrays de datos y etiquetas\n",
    "5. División en conjuntos de entrenamiento, validación y test\n",
    "6. Definición, entrenamiento y evaluación del modelo\n",
    "\n",
    "Cada sección está documentada para facilitar la revisión y comprensión del proceso por parte del profesor.\n",
    "\n",
    "**Asegúrate de tener tu archivo `kaggle.json` para descargar el dataset desde Kaggle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb194465",
   "metadata": {},
   "source": [
    "## 1. Instalación de dependencias y configuración de entorno Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad07447",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle opencv-python-headless seaborn tensorflow scikit-learn --quiet\n",
    "import os, shutil, zipfile, cv2, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbadd9",
   "metadata": {},
   "source": [
    "## 2. Descarga del dataset desde Kaggle\n",
    "Se descarga el dataset de imágenes MRI desde Kaggle y se prepara la estructura de carpetas necesaria en el entorno de Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e207ab",
   "metadata": {},
   "source": [
    "## 2. Descarga del dataset desde Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b150036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
    "!kaggle datasets download -d orvile/brain-cancer-mri-dataset -p /content/data --unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca983d15",
   "metadata": {},
   "source": [
    "## 3. Reorganización y verificación de carpetas\n",
    "Se reorganizan las carpetas de clases y se verifica la cantidad de imágenes disponibles por clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08be487",
   "metadata": {},
   "source": [
    "## 3. Reorganización y verificación de carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697259c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/content/data/original', exist_ok=True)\n",
    "clases = ['brain_glioma', 'brain_menin', 'brain_tumor']\n",
    "for root, dirs, files in os.walk('/content/data'):\n",
    "    for clase in clases:\n",
    "        if clase in dirs:\n",
    "            origen = os.path.join(root, clase)\n",
    "            destino = f'/content/data/original/{clase}'\n",
    "            if origen != destino and not os.path.exists(destino):\n",
    "                shutil.move(origen, destino)\n",
    "for dirpath, dirnames, filenames in os.walk('/content/data', topdown=False):\n",
    "    if dirpath == '/content/data': continue\n",
    "    if not dirnames and not filenames:\n",
    "        os.rmdir(dirpath)\n",
    "for clase in clases:\n",
    "    n = len(glob(f'/content/data/original/{clase}/*.jpg'))\n",
    "    print(f'{clase}: {n} imágenes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70353fe1",
   "metadata": {},
   "source": [
    "## 4. Preprocesado de imágenes y guardado\n",
    "Se aplica el preprocesamiento a las imágenes originales y se guardan las imágenes procesadas en carpetas separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c8948",
   "metadata": {},
   "source": [
    "## 4. Preprocesado de imágenes y guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb318d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_imagen(img_path, size=(128,128)):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        try:\n",
    "            with Image.open(img_path) as pil_img:\n",
    "                img = np.array(pil_img.convert('L'))\n",
    "        except Exception as e:\n",
    "            print(f'[ERROR] No se pudo cargar la imagen: {img_path} ({e})')\n",
    "            return np.zeros(size)\n",
    "    _, thresh = cv2.threshold(img, 5, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        img = img[y:y+h, x:x+w]\n",
    "    img = cv2.resize(img, size)\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img.astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "    return img\n",
    "\n",
    "os.makedirs('/content/data/preprocesadas', exist_ok=True)\n",
    "for clase in clases:\n",
    "    out_dir = f'/content/data/preprocesadas/{clase}'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for img_path in glob(f'/content/data/original/{clase}/*.jpg'):\n",
    "        img_proc = preprocesar_imagen(img_path)\n",
    "        img_uint8 = (img_proc * 255).clip(0,255).astype(np.uint8)\n",
    "        Image.fromarray(img_uint8).save(os.path.join(out_dir, os.path.basename(img_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fe209",
   "metadata": {},
   "source": [
    "## 5. Preparación de arrays de datos y etiquetas\n",
    "Se cargan las imágenes preprocesadas, se convierten en arrays NumPy y se generan las etiquetas correspondientes para su uso en el modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40193b4e",
   "metadata": {},
   "source": [
    "## 5. Preparación de arrays de datos y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "clase_a_idx = {c: i for i, c in enumerate(clases)}\n",
    "n_imagenes = 2000\n",
    "for clase in clases:\n",
    "    imgs = glob(f'/content/data/preprocesadas/{clase}/*.jpg')[:n_imagenes]\n",
    "    for img_path in imgs:\n",
    "        img = preprocesar_imagen(img_path, size=(128,128))\n",
    "        X.append(img)\n",
    "        y.append(clase_a_idx[clase])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X.astype('float32') / 255.0\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "print('Shape X:', X.shape)\n",
    "print('Shape y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cc843",
   "metadata": {},
   "source": [
    "## 6. División en train, val y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddabd06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y, num_classes=len(clases))\n",
    "# División: 70% train, 15% val, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_cat, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=np.argmax(y_temp, axis=1), random_state=42)\n",
    "print(f'Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03691629",
   "metadata": {},
   "source": [
    "## 7. Modelado: Definición y entrenamiento de una CNN simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa578a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura óptima basada en la versión local\n",
    "def crear_modelo(conv_filters, dense_units, dropout_conv, dropout_dense, lr):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(conv_filters[0], (3,3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(dropout_conv))\n",
    "    model.add(Conv2D(conv_filters[1], (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(dropout_conv))\n",
    "    model.add(Conv2D(conv_filters[2], (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(dropout_conv + 0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_dense))\n",
    "    model.add(Dense(len(clases), activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "# Hiperparámetros óptimos\n",
    "best_params = {\n",
    "    'conv_filters': [16, 32, 64],\n",
    "    'dense_units': 64,\n",
    "    'dropout_conv': 0.1,\n",
    "    'dropout_dense': 0.1,\n",
    "    'lr': 0.0005\n",
    "}\n",
    "model = crear_modelo(**best_params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad857da",
   "metadata": {},
   "source": [
    "## 8. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ce6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "# Visualización de la historia de entrenamiento\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Precisión durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2872abd",
   "metadata": {},
   "source": [
    "## 9. Evaluación y visualización de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación en test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión en test: {test_acc:.4f}')\n",
    "# Matriz de confusión\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=clases, yticklabels=clases)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.show()\n",
    "# Reporte de clasificación\n",
    "print(classification_report(y_true, y_pred, target_names=clases))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
