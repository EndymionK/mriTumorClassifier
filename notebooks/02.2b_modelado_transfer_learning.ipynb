{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0893f28",
   "metadata": {},
   "source": [
    "# Clasificación de Tumores Cerebrales en MRI con Transfer Learning (VGG16)\n",
    "Este notebook implementa un pipeline de modelado usando transfer learning con VGG16 preentrenada, data augmentation y fine-tuning para clasificación de tumores cerebrales en imágenes MRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2167da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importar librerías necesarias\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bcbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cargar imágenes preprocesadas y preparar splits para transfer learning\n",
    "DATA_PATH = '../data/preprocesadas'\n",
    "CLASES = ['brain_glioma', 'brain_menin', 'brain_tumor']\n",
    "IMG_SIZE = (224, 224)\n",
    "N_CHANNELS = 3  # Para VGG16\n",
    "X = []\n",
    "y = []\n",
    "for idx, clase in enumerate(CLASES):\n",
    "    ruta_clase = os.path.join(DATA_PATH, clase)\n",
    "    imagenes = glob(os.path.join(ruta_clase, '*.jpg'))\n",
    "    for img_path in imagenes:\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img = img.resize(IMG_SIZE)\n",
    "        img = np.array(img)\n",
    "        # Adaptar a 3 canales duplicando\n",
    "        img_rgb = np.stack([img]*3, axis=-1)\n",
    "        X.append(img_rgb)\n",
    "        y.append(idx)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print('Shape X:', X.shape)\n",
    "print('Shape y:', y.shape)\n",
    "\n",
    "# Normalizar a [0,1]\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding de etiquetas\n",
    "y_cat = to_categorical(y, num_classes=len(CLASES))\n",
    "\n",
    "# Split train/val/test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_cat, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=np.argmax(y_temp, axis=1), random_state=42)\n",
    "print(f'Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data augmentation y visualización de ejemplos aumentados\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    " )\n",
    "\n",
    "# Visualizar algunos ejemplos aumentados\n",
    "sample_idx = np.random.choice(len(X_train), 1)[0]\n",
    "img = X_train[sample_idx]\n",
    "img = np.expand_dims(img, 0)\n",
    "aug_iter = datagen.flow(img, batch_size=1)\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    batch = next(aug_iter)[0]\n",
    "    plt.imshow(batch.astype('float32'))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Ejemplos de data augmentation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac050e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Definir modelo VGG16 preentrenado y cabeza personalizada\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Congelar capas base\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(len(CLASES), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Entrenamiento de la cabeza del modelo (solo capas densas)\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_vgg16_head.h5', save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "train_gen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_gen = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualización de resultados y guardado del modelo final\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Curvas de entrenamiento\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluación en test\n",
    "preds = model.predict(X_test)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASES, yticklabels=CLASES)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de confusión en test')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación\n",
    "print('Reporte de clasificación en test:')\n",
    "print(classification_report(y_true, y_pred, target_names=CLASES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo final con precisión de validación en el nombre\n",
    "MODELOS_DIR = '../models'\n",
    "os.makedirs(MODELOS_DIR, exist_ok=True)\n",
    "fecha_hora = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "val_acc_final = max(history.history['val_accuracy'])\n",
    "nombre_modelo = f\"cnn_mri_{fecha_hora}_valacc_{val_acc_final:.4f}.h5\"\n",
    "ruta_modelo = os.path.join(MODELOS_DIR, nombre_modelo)\n",
    "model.save(ruta_modelo)\n",
    "print(f\"Modelo final guardado en: {ruta_modelo}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
